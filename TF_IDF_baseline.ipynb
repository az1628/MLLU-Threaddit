{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF-IDF.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Szs5t9A-3HJj",
        "colab_type": "code",
        "outputId": "a2f1cccf-2306-4eee-865f-8a96b41e368b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "pip install jsonlines"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting jsonlines\n",
            "  Downloading https://files.pythonhosted.org/packages/4f/9a/ab96291470e305504aa4b7a2e0ec132e930da89eb3ca7a82fbe03167c131/jsonlines-1.2.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from jsonlines) (1.12.0)\n",
            "Installing collected packages: jsonlines\n",
            "Successfully installed jsonlines-1.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uZh3qB5C-KC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "import jsonlines\n",
        "import json\n",
        "from glob import glob\n",
        "l=[]\n",
        "with open('train.jsonl', \"r\") as f:\n",
        "\n",
        "    for line in f.readlines():\n",
        "        l.append(json.loads(line))\n",
        "        \n",
        "train_set= l[0:int(len(l)*0.8)]\n",
        "\n",
        "test_set = l[int(len(l)*0.8)+1:]\n",
        "\n",
        "train_loader=[]\n",
        "\n",
        "for i in train_set:\n",
        "\n",
        "    for j in range(4):\n",
        "        \n",
        "        train_loader.append([i[\"parent\"]+\" <SEP> \" +i[\"response\"] , i[\"child_comment_\" + str(j)]])\n",
        "#taking transpose of the train_loader\n",
        "train_loader= list(map(list, zip(*train_loader)))\n",
        "\n",
        "\n",
        "test_loader_contexts =[]\n",
        "test_loader_responses =[]\n",
        "\n",
        "\n",
        "for i in test_set:\n",
        "    \n",
        "        test_loader_contexts.append([str(i[\"parent\"]+\" <SEP> \" +i[\"response\"]), str(i[\"parent\"]+\" <SEP> \" +i[\"response\"]),str(i[\"parent\"]+\" <SEP> \" +i[\"response\"]),str(i[\"parent\"]+\" <SEP> \" +i[\"response\"])] )\n",
        "        test_loader_responses.append([i[\"child_comment_\" + str(0)],i[\"child_comment_\" + str(1)],i[\"child_comment_\" + str(2)],i[\"child_comment_\" + str(3)],i[\"label\"]])\n",
        "        \n",
        "    \n",
        "\n",
        "#test_loader = list(map(list, zip(*test_loader)))\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bgXzvTUDFfA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "from sklearn.feature_extraction.text import (HashingVectorizer,\n",
        "                                             TfidfTransformer,\n",
        "                                             _document_frequency)\n",
        "from sklearn.utils.testing import ignore_warnings\n",
        "import method\n",
        "\n",
        "\n",
        "class TfIdfMethod(method.BaselineMethod):\n",
        "\n",
        "    \"\"\"TF-IDF baseline.\n",
        "    This hashes words to sparse IDs, and then computes tf-idf statistics for\n",
        "    these hashed IDs. As a result, no words are considered out-of-vocabulary.\n",
        "    \"\"\"\n",
        "    def train(self, contexts, responses):\n",
        "        \"\"\"Fit the tf-idf transform and compute idf statistics.\"\"\"\n",
        "        self._vectorizer = HashingVectorizer()\n",
        "        self._tfidf_transform = TfidfTransformer()\n",
        "        \n",
        "        self._tfidf_transform.fit(\n",
        "            self._vectorizer.transform(contexts + responses))\n",
        "\n",
        "    def _vectorize(self, strings):\n",
        "        \"\"\"Vectorize the given strings.\"\"\"\n",
        "        tf_idf_vectors = self._tfidf_transform.transform(\n",
        "            self._vectorizer.transform(strings))\n",
        "        return sp.csr_matrix(\n",
        "            tf_idf_vectors, dtype=np.float64, copy=True)\n",
        "\n",
        "    def rank_responses(self, contexts, responses):\n",
        "        \"\"\"Rank the responses for each context.\"\"\"\n",
        "        contexts_matrix = self._vectorize(contexts)\n",
        "        responses_matrix = self._vectorize(responses)\n",
        "        similarities = contexts_matrix.dot(responses_matrix.T).toarray()\n",
        "        return np.argmax(similarities, axis=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrBnb-cMDN0N",
        "colab_type": "code",
        "outputId": "6eb66c8f-42ae-4f0c-a0ff-56f84721e080",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def train(model):\n",
        "  model= TfIdfMethod() \n",
        "  model.train(train_loader[0],train_loader[1])\n",
        "  return model\n",
        "\n",
        "\n",
        "def evaluate(model):\n",
        "    total =0\n",
        "    correct =0\n",
        "    for i in range(len(test_loader_contexts)):\n",
        "        a = test_loader_contexts[i]\n",
        "        b = test_loader_responses[i]\n",
        "        predicted_label = model.rank_responses([a[0],a[1],a[2],a[3]],[b[0],b[1],b[2],b[3]])[0]\n",
        "        #check if label matches\n",
        "        #print(b[4])\n",
        "        #print(predicted_label)\n",
        "\n",
        "        #print(\"A\")\n",
        "        if int(predicted_label)==int(b[4]):\n",
        "            correct+=1\n",
        "        total+=1\n",
        "        \n",
        "        #print(predicted_label)\n",
        "    return correct/total\n",
        "model = None\n",
        "model = train(model)\n",
        "evaluate(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3721028234302571"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    }
  ]
}